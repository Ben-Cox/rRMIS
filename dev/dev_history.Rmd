---
title: "dev_history.Rmd for RMIS data package"
author: "Ben Cox"
date: "23/01/2021"
output: html_document
---

```{r development, include=FALSE}
library(testthat)
```

<!--
# Description of your package
This will fill the description of your package.
Add this chunk using `fusen::description_chunk()`
--> 


```{r description,eval=FALSE}
# Describe your package
fusen::fill_description(
  fields = list(
    Title = "rRMIS",
    Description = "Download CWT release or recovery data from RMIS ftp text files.",
    `Authors@R` = c(person("Ben", "Cox", email = "benjamin.cox@dfw.wa.gov", role = c("aut", "cre"))),
    `Imports`="lubridate, RCurl",
    #`@importFrom`="magrittr %>%",
   # `@importFrom`="RCurl getURL",
    `Depends`="dplyr, readr, doParallel, foreach, parallel"
  ),
  overwrite=TRUE
)
# Define License with use_*_license()
#usethis::use_mit_license("Ben Cox")
#usethis::use_package("tidyverse",type="Depends")
#usethis::use_package("doParallel",type="Depends")
#usethis::use_package("foreach",type="Depends")
#usethis::use_package("parallel",type="Depends")
#usethis::use_package("lubridate",type="Imports")
```

```{r function-1}
#' Download release data from RMIS
#'
#' @param url the url to the full CWT release data set on the RMIS ftp server
#' @param dir Directory to save downloaded file. If `NULL` (the default), saves in Data in working directory.
#'
#' @return `NULL` 
#' @return Saves file locally.
#'
#' @export
#'
#' @examples download_releases()
download_releases <- function(file="RL041_ALL_FULLSET.zip", dir="RMIS"){
  #if(is.null(dir)) dir <- "RMIS"
  url <- file.path(get("url",env=RMIS.globals), file)
  #dir <- file.path(url, file)
  if(!dir.exists(dir)) dir.create(dir,recursive=TRUE)
  message("Downloading Release data from RMIS to ~./", dir,".")
  download.file(url=url, 
                destfile=file.path(dir,"RL041_ALL_FULLSET.zip"), 
                quiet=TRUE)
}

RMIS.globals <- new.env()
RMIS.globals$url <- "ftp://ftp.rmpc.org/pub/data"
RMIS.globals$rel_file <- "RL041_ALL_FULLSET.zip"

```

```{r function-2}
#' Download RMIS LUTs
#' @description Downloads lookup tables from RMIS ftp server.
#' @param url url to RMIS ftp serer 
#' @param lut_dir Directory to save RMIS lookup tables. If `NULL` (the default) puts luts in a RMIS_LUTs folder in working directory.
#' @return `NULL`
#' @return Downloads lookup tables from RMIS into chosen dir
#' @export
download_luts <- function(lut_dir="RMIS/LUTs"){
  #require(parallel)
  #require(doParallel)
  #require(foreach)
url <- get("url",RMIS.globals)
 # if(is.null(dir)) {dir <- "RMIS/LUTs"}
    if(!dir.exists(lut_dir)) {dir.create(lut_dir,recursive=TRUE) }

  #lut_dir <- dir
  
  lut_filenames <- c("LC041_ALL_FULLSET.zip",
                    "run.zip",
                    "species.zip",
                    "study_type.zip",
                    "marks.zip",
                    "location_type.zip",
                    "gear.zip", 
                    "fishery.zip",
                    "period.zip",
                    "adclip_selective_fishery.csv"
                    )

    ftp_paths <- file.path(url, lut_filenames)
    dest_paths <- file.path(lut_dir, lut_filenames)                
   
       cl <- parallel::makeCluster(parallel::detectCores())
      
       doParallel::registerDoParallel(cl=cl)
     
message("Downloading LUTs from RMIS to ~./",lut_dir,".")

  foreach::foreach(i=seq_along(ftp_paths)) %dopar% {
    download.file(url=ftp_paths[i], destfile=dest_paths[i], quiet=TRUE)
    } %>% 
      invisible()
    stopCluster(cl)
} 


```

```{r function-3}
#' Make a list of files to download
#' @description Creates a list of files to download for desired years of CWT recovery data.
#' @param startYear First year of desired CWT recovery data
#' @param endYear  Last year of desired CWT recovery data
#' @param RMIS_url URL to RMIS ftp server
#' @param temp_dir File to hold downloaded csv's
#' @importFrom RCurl getURL
#' @return A list with download urls for each file and destination paths for each file
#' @export
#' @examples
make_file_list <- function(startYear, 
                              endYear,
                              RMIS_url="ftp://ftp.rmpc.org/pub/data/", 
                              dir=NULL) {
# # Error message
#   if(is.null(startYear) | is.null(endYear)) {

#     return(message("ERROR: Please supply start and/or end year"))
#   }
  
  # load pkgs required for this function
    #using("RCurl", "tidyverse")
  
# Get filenames in the RMIS ftp directory - Takes a minute
ftp_names <- RCurl::getURL(RMIS_url, dirlistonly = TRUE)

# Make a vector of filenames, separating by line breaks ("\n")
  filenames <- strsplit(ftp_names, "\n") [[1]]

# Only want the csv files, use the regex below to grab only files beginning with RC041_ and ending with .csv
    # Changed to .zip to help with download speed. readr can read from local zips but not url .zips
  csvs <- filenames[grep("^RC041_.*\\.zip", filenames)]

  #  Only grab ODFW/WDFW files, replace line 22 with:
  #   csvs <-  filenames[grep("^RC041_ODFW.*\\.csv | ^RC041_WDFW.*\\.csv", filenames,fixed=F)]

# Extract the years for each recovery filename,convert to number. used to filter out years we don't need
  yrs <- substr(csvs, start=nchar(csvs)-8, nchar(csvs)-5) %>% as.integer

# Subset the csv filenames for only the years we want, drop the "\r" from filenames (for when we go to download) 
  files <- csvs[which(yrs >= startYear & yrs<=endYear)] %>% substr(1, nchar(.)-1)

# Return the list with a vector of file urls and the local path to save the downloaded files
  list(download_urls=paste0(RMIS_url, files), files=file.path(dir,files))
}

```

```{r function-4}
#' Download CWT recoveries
#'
#' @param start_yr First year of recoveries 
#' @param end_yr  Last year of recoveries
#' @param dir Directory to save downloaded files, if `NULL` creates Data/Recoveries/temp in working directory.
#' @param by_brood  `TRUE` (default) if start and end years are in terms of brood years
#'
#' @return `NULL`
#' @return Downloads .zip files of recovery data to local dir
#' @export
#'
#' @examples
download_recoveries <- function(start_yr, end_yr, by_brood=TRUE, dir="RMIS/Recoveries") {

  #if(is.null(dir)) dir <- "RMIS/Recoveries"
  if(!dir.exists(dir)){dir.create(dir, recursive=TRUE)}

  if(by_brood){
    
  startYear <- start_yr + 2
  endYear <- end_yr + 7
  
  }else{
    startYear <- start_yr
    endYear <- end_yr
  }
  
  curYear <- lubridate::year(Sys.Date())
  
  if (startYear > (curYear-1) || (endYear > (curYear-1))){
    warning(paste0("Chosen brood year(s) may not be fully reported to RMIS"))
    }
  
  # BUILD TEST FOR COMPLETED BROODs- maybe year(sys.Date()-1)?
  #if(endYear>)
   # Create list with the file  paths
      file_list <- make_file_list(startYear, endYear, dir=dir)

    # Set up clusters for parallel downloads
      cl <- makeCluster(detectCores())
        
      registerDoParallel(cl=cl)
      
message("This could take a while.")

  # Do download, read and combine the csvs with parallel for loop
     foreach(i=seq_along(file_list[[1]]), .inorder=FALSE) %dopar% {

      # Download the files from download urls, save them to the local paths
       download.file(url=file_list$download_urls[i], destfile=file_list$files[i], quiet=TRUE)
       
    }
    
stopCluster(cl)

}

```

```{r function-5}
#' Read release data
#'
#' @param first_by first brood year of data
#' @param last_by  last brood year of data
#' @param dir Directory where release data were downloaded
#' @import readr
#' @return A data frame of the raw RMIS release data, filtered for brood years between first_by and last_by (inclusive)
#' @export
#' @examples
read_releases <- function(first_by=NULL, last_by=NULL, dir="RMIS"){
  require(readr)
 # if(is.null(dir)){dir <- "RMIS"}
  file <- file.path(dir, "RL041_ALL_FULLSET.zip")
  
  if(!file.exists(file)){download_releases(dir=dir)}
  
 if (!is.null(first_by) & !is.null(last_by)) {  
  read_csv(file, 
           col_types=cols(.default="c",
                          species="i",
                          run="i",
                          avg_weight="d",
                          cwt_1st_mark_count="d",
                          cwt_2nd_mark_count="d",
                          non_cwt_1st_mark_count="d",
                          non_cwt_2nd_mark_count="d",
                          brood_year="i",
                          tag_loss_rate="d",
                          avg_length="d",
                          tag_loss_sample_size="i",
                          tag_loss_days="d"), 
           progress=FALSE)%>% 
    # Filter for Chinook (1) and Coho (2)
    filter( brood_year >= first_by, 
            brood_year <= last_by)
 } else {
   read_csv(file, 
           col_types=cols(.default="c",
                          species="i",
                          run="i",
                          avg_weight="d",
                          cwt_1st_mark_count="d",
                          cwt_2nd_mark_count="d",
                          non_cwt_1st_mark_count="d",
                          non_cwt_2nd_mark_count="d",
                          brood_year="i",
                          tag_loss_rate="d",
                          avg_length="d",
                          tag_loss_sample_size="i",
                          tag_loss_days="d"), 
           progress=FALSE)
  
 }
}  


```

```{r function-6}
#' Lookup foreign keys in RMIS release data
#'
#' @param RMIS_releases read in from read_releases()
#' @param lut_dir Directory with RMIS lookup tables if `NULL` (default) looks in Data/RMIS_LUTs 
#' @return Dataframe of RMIS release data with decoded field names.
#' @export
#'
decode_release_data <- function(RMIS_releases, lut_dir="RMIS/LUTs"){
 
  if(!dir.exists(lut_dir) | length(list.files(lut_dir))==0){
    download_luts(lut_dir=lut_dir)
    }
  
 # Read lookup tables
  RMIS_locations <- read_csv(file.path(lut_dir,"LC041_ALL_FULLSET.zip"), col_types=cols(.default="c"),progress=FALSE)
  RMIS_runs <- read_csv(file.path(lut_dir,"run.zip"), col_types=cols(.default="c",run="i"),progress=FALSE)
  RMIS_species <- read_csv(file.path(lut_dir,"species.zip"), col_types=cols(.default="c",species="i"),progress=FALSE)
  RMIS_studytype <- read_csv(file.path(lut_dir,"study_type.zip"), col_types=cols(.default="c"),progress=FALSE)
  
  missing_release_locs <- which(is.na(RMIS_releases$release_location_code) | 
                                  RMIS_releases$release_location_code=="" | 
                                  grepl("TEMP",RMIS_releases$release_location_code))

  missing_domains <- RMIS_releases %>% 
    dplyr::filter(grepl("TEMP", .$release_location_code) | is.na(release_location_code) | release_location_code == "") %>% 
  left_join(filter(RMIS_locations, location_type == 3), by=c("hatchery_location_code"="location_code")) %>% 
  select(tag_code_or_release_id, psc_region) %>% 
  left_join(RMIS_domain, by=c("psc_region"="rmis_region")) %>% 
    select(rmis_domain)

CR_rel_data <- 

  # Filter the releases for brood years, grab all years for both release summary and tag recoveries  
  RMIS_releases %>% 
  # Then join to the location table (type 4 = release locations) to lookup the release site name and psc region
    left_join(
    
    #Select just the location code and name from the locations table to join to the releases
      select(filter(RMIS_locations,location_type==4), location_code, release_site=name, psc_region),
  
    #Join the release data to the filtered location table (line above) by release location code and RelCode (named in line above: "RelCode=location_code")
      by=c("release_location_code"="location_code")) %>% 
  
    # Join the psc region looked up above to the rmis_domain table to lookup the RMIS domain,
      left_join(RMIS_domain, by=c("psc_region"="rmis_region")) %>%
  
    # Join to the location table again, this time lookup hatchery name
      left_join(
      select(filter(RMIS_locations, location_type==3), location_code, hatchery=name),
      by=c("hatchery_location_code"="location_code")) %>%
    
    # Join to location table one last time to lookup stock name
      left_join(
      select(filter(RMIS_locations, location_type==5), location_code, stock=name),
      by=c("stock_location_code"="location_code")) %>%   
  
    left_join(select(RMIS_species, species, species_name), by=c("species")) %>% 
    left_join(RMIS_runs, by="run") %>% 
    left_join(RMIS_studytype, by="study_type") %>% 
  
    mutate(release_year=substr(last_release_date, 1, 4)) #%>%
  
    # Finally, select only the columns needed.
    #select(record_code,tag_code_or_release_id,reporting_agency, species=species_name, run=run_name, tag_code_or_release_id, Hatchery, Stock, RelSite,brood_year,first_release_date, last_release_date,release_year,rmis_domain,
    #       cwt_1st_mark, cwt_1st_mark_count,non_cwt_1st_mark,non_cwt_1st_mark_count,cwt_2nd_mark,
    #       cwt_2nd_mark_count,non_cwt_2nd_mark,non_cwt_2nd_mark_count,release_location_code,study_type=study_type_name,avg_weight,rel_id,comp_key)

# Lookup the rmis domain for the missing domains, replace in CR_rel_data
CR_rel_data[which(is.na(CR_rel_data$rmis_domain)), "rmis_domain"] <- 
  
  CR_rel_data[which(is.na(CR_rel_data$rmis_domain)),] %>% 
  left_join(filter(RMIS_locations,location_type==3), by=c("hatchery_location_code"="location_code")) %>%
  left_join(RMIS_domain, by=c("psc_region.y"="rmis_region")) %>% 
  select(rmis_domain.y)

# Check for agencies with releases having undefined domains
agencies_no_domain <- CR_rel_data %>% 
  filter(is.na(rmis_domain)) %>% 
  select(release_agency) %>% 
  distinct()

# # Print warning for missing rmis_domains. Col R are usually reported, have seen WDFW coastal data with no domain
# if(nrow(agencies_no_domain)>0){
#   warning(paste(nrow(agencies_no_domain),"agencies have undefined release domains."), 
#           paste(c(" Agencies include:", pull(agencies_no_domain, release_agency)), collapse=" "))
# }

# Change release date to date format
 CR_rel_data %>% 
mutate_at(vars(contains("release_date")),~suppressWarnings(lubridate::ymd(.x)))

 }

```

```{r function-7}
#' Filter and combine recoveries
#'
#' @param first_by 
#' @param last_by 
#' @param rec_dir Directory where recovery data were downloaded
#' @param ... filter conditions for RMIS fields in release data 
#' @importFrom rlang quos
#' @importFrom rlang !!!
#' @return
#' @export
#'
#' @examples
filter_and_combine_recoveries <- function(first_by, last_by, ..., rec_dir="RMIS/Recoveries", lut_dir="RMIS/LUTs" ){
  
  if(!dir.exists(rec_dir) || length(list.files(rec_dir))==0){stop("No recovery data found")}
  
  # Create quosure for filter conditions passed in: need to document examples. 
  # Can pass in any filter conditions using RMIS field names.
  filter_conditions <- rlang::quos(...)

  files <- list.files(rec_dir, full.names=TRUE)

  Releases <- read_releases() %>% decode_release_data()
  
  species_lu <- read_csv(file.path(lut_dir,"species.zip"), 
                         col_types=cols(species=col_integer(), 
                                        species_name=col_character(),
                                        species_name=col_character())) %>% 
                select(species,species_name)
                                                                 
  # Set up clusters for parallel read/filter/combine
      cl <- makeCluster(detectCores())
      
  # Register cluster      
      registerDoParallel(cl=cl)  
  message("Reading recovery files, please be patient.")
# Read, lookup release info, filter in parallel
df <- foreach(i=seq_along(files), .combine=rbind, .inorder=FALSE, .packages=c("tidyverse")) %dopar% {

    read_csv(files[i], col_types=cols(.default="c", 
                                      recovery_date=col_date(format="%Y%m%d"),
                                      run_year=col_integer(),
                                      species=col_integer(),
                                      estimated_number=col_double())) %>%
    # Look up recovery species
    left_join(species_lu, by="species") %>% 
    # Look up release info
    left_join(Releases, by=c("tag_code"="tag_code_or_release_id"), suffix=c("_recovery","")) %>%
   
    # Filter by conditions passed in as '...'
    filter(# Type 5 recoveries can lead to double counting, check RMIS manual
           sample_type!=5, 
           # Only succesfully decoded recoveries
           tag_status==1,
           brood_year>=first_by,
           brood_year<=last_by,
           run_year>=first_by+2,
           run_year<=last_by+7) %>% 
    tidy_recoveries(lut_dir=lut_dir) %>% 
    filter(!!!filter_conditions)
  } # End parallel for loop

    # Stop the parallel cluster
        stopCluster(cl)
  
#  Return df      
  df
      
    # Write out the combined dataframe as a csv
    #write.csv(df, paste0("GatherData/", "recoveries.csv"),row.names=FALSE)
    
    # Delete the downloaded csvs in the temp directory
      #file.remove(file_list$local_paths) %>% invisible()
  
}

```

```{r function-8}
#' Lookup recovery location/fishery info
#'
#' @param recoveries A dataframe of recovery data from RMIS
#'
#' @return A dataframe with foreign keys decoded from LUTs
#' @export
#'
#' @examples
tidy_recoveries <- function(recoveries,lut_dir="RMIS/LUTs") {
  #using("readxl") 
  
  RMIS_recoveries <- recoveries %>%  mutate(temp_prefix = NA)#overies 

  gear_lu <- read_csv(file.path(lut_dir,"gear.zip"), col_types = cols(fishery = "d"))
  
  fishery_lu2 <- read_csv(file.path(lut_dir,"fishery.zip"), col_types = cols(fishery = "d"))
  
  RMIS_locations <- read_csv(file.path(lut_dir,"LC041_ALL_FULLSET.zip"), col_types = cols(.default = "c"), progress=FALSE)

  # Get unique recovery location/fishery rows from recoveries, used to create a mgt fishery lut for the recoveries
    unique_rec_locs <- RMIS_recoveries %>% select(recovery_location_code,fishery) %>% distinct() %>% mutate(temp_prefix=NA)

  # Matches the fishery prefix to corresponding row(s) in the fishery_lu
    mgt_fishery_lu <-
  
    sapply(1:nrow(unique_rec_locs), function(x)
  which(startsWith(unique_rec_locs$recovery_location_code[x], prefix = fishery_lu$location_code_prefix) &
          unique_rec_locs$fishery[x] >= fishery_lu$starting_psc_fishery & unique_rec_locs$fishery[x] <= fishery_lu$ending_psc_fishery)
      )

  no_codes <-
    sapply(1:length(mgt_fishery_lu), function(x)
      length(mgt_fishery_lu[[x]])) == 0
  
  
  unique_rec_locs$temp_prefix[no_codes] <- "X"
  
  mgt_fishery_lu[which(unique_rec_locs$temp_prefix == "X")] <-
    sapply(which(unique_rec_locs$temp_prefix == "X"), function(x)
      which(
        startsWith(unique_rec_locs$temp_prefix[x], prefix = fishery_lu$location_code_prefix) &
          unique_rec_locs$fishery[x] >= fishery_lu$starting_psc_fishery &
          unique_rec_locs$fishery[x] <= fishery_lu$ending_psc_fishery
      ))
  
  no_codes <-
    sapply(1:length(mgt_fishery_lu), function(x)
      length(mgt_fishery_lu[[x]])) == 0
  
  mgt_fishery_lu[no_codes] <- NA
  
  # Matches with >1 corresponding fishery codes
  to_fix <-sapply(1:length(mgt_fishery_lu), function(x) length(mgt_fishery_lu[[x]])) > 1
  
  if(any(to_fix)){
  # Replace with the longest match
    for (i in 1:length(mgt_fishery_lu[to_fix])) {
      mgt_fishery_lu[to_fix][[i]] <- mgt_fishery_lu[to_fix][[i]][which.max(nchar(fishery_lu$location_code_prefix[mgt_fishery_lu[to_fix][[i]]]))]
    }
  }
  
  mgt_fishery_lu <- unlist(mgt_fishery_lu)
  
  rec_fishery_lu <- bind_cols(unique_rec_locs, mgt_fishery=fishery_lu$mgt_fishery_name[mgt_fishery_lu]) %>% 
                    select(- temp_prefix)

  RMIS_recoveries %>% 
    left_join(rec_fishery_lu, by=c("recovery_location_code","fishery")) %>% 
    #select(tag_code,recovery_date,mgt_fishery) %>% 
    left_join(select(filter(RMIS_locations,location_type==1), location_code, recovery_location=name, description, psc_region), by=c("recovery_location_code"="location_code")) %>% 
    left_join(fishery_lu2 %>% mutate(fishery=as.character(fishery)),by="fishery") %>% 
    left_join(gear_lu %>% mutate(fishery=as.character(fishery)), by = c("reporting_agency_recovery"="reporting_agency", "fishery", "gear")) %>% 
    mutate(age=run_year - brood_year)
      
}

```

```{r function-9}
#' Download dataframe of the RMIS release data
#'
#' @param first_by first brood year of releases 
#' @param last_by  last brood year of releases
#' @param dir directory where releases are held if `NULL` (the default) creates a Data folder in working directory.
#' @param lut_dir directory where releases are held
#' @param dl_now  Logical determines if release file should be downloaded now (if already present in `rel_dir`). Defaults to FALSE.
#' @return A dataframe of the RMIS release data with foreign keys decoded.
#' @export
#'
get_release_data <- function(first_by=NULL, last_by=NULL, rel_dir="RMIS",lut_dir="RMIS/LUTs", dl_now=FALSE){
  #if(is.null(dir))dir <- "RMIS"
  rel_file <- file.path(rel_dir,"RL041_ALL_FULLSET.zip")
 
  if((file.exists(rel_file) & dl_now==TRUE) | !file.exists(rel_file)) {
    download_releases(dir=rel_dir)
    download_luts(lut_dir=lut_dir)
    }
  
  read_releases(first_by=first_by, 
                last_by=last_by,
                dir=rel_dir) %>% 
    decode_release_data(lut_dir=lut_dir)
}
```

```{r function-10}
#' set the RMIS ftp url
#'
#' @param url 
#'
#' @return
#' @export
#'
#' @examples
set_url <- function (url) {
    RMIS.globals$url <- url
}
```




# There can be development actions

These will be included in the `dev_history.R` file of your package, but won't be direct part of it.

```{r development-1, eval=FALSE}
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly
fusen::inflate(rmd = "dev/dev_history.Rmd")
```

```{r development-2, eval=FALSE}
# Add fishery map lookup to internal data, this table comes from Jim Longwill. Not on RMIS website
library(readxl)
fishery_lu <-read_xlsx("RMIS_LUTs/rmis_rar_fishery_map.xlsx", sheet = "rar_original_fishery_map", trim_ws = TRUE, progress = FALSE)

usethis::use_data(fishery_lu)

```


# Inflate your package

You're one inflate from paper to box.
Build your package from this very Rmarkdown using `fusen::inflate()`

- Verify your `"DESCRIPTION"` file has been updated
- Verify your function is in `"R/"` directory
- Verify your test is in `"tests/testthat/"` directory
- Verify this Rmd appears in `"vignettes/"` directory

