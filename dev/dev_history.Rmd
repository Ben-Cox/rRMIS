---
title: "dev_history.Rmd for RMIS data package"
author: "Ben Cox"
date: "23/01/2021"
output: html_document
---

```{r development, include=FALSE}
library(testthat)
```

<!--
# Description of your package
This will fill the description of your package.
Add this chunk using `fusen::description_chunk()`
--> 


```{r description,eval=FALSE}
# Describe your package
fusen::fill_description(
  fields = list(
    Title = "rRMIS",
    Description = "Download CWT release or recovery data from RMIS ftp text files.",
    `Authors@R` = c(person("Ben", "Cox", email = "benjamin.cox@dfw.wa.gov", role = c("aut", "cre"))),
    `Imports`="lubridate, RCurl",
    #`@importFrom`="magrittr %>%",
   # `@importFrom`="RCurl getURL",
    `Depends`="dplyr, readr, doParallel, foreach, parallel"
  ),
  overwrite=TRUE
)
# Define License with use_*_license()
#usethis::use_mit_license("Ben Cox")
#usethis::use_package("tidyverse",type="Depends")
#usethis::use_package("doParallel",type="Depends")
#usethis::use_package("foreach",type="Depends")
#usethis::use_package("parallel",type="Depends")
#usethis::use_package("lubridate",type="Imports")
```

```{r function-1}
#' Download release data from RMIS
#'
#' @param url the url to the full CWT release data set on the RMIS ftp server
#' @param dir Directory to save downloaded file. If `NULL` (the default), saves in Data in working directory.
#'
#' @return `NULL` 
#' @return Saves file locally.
#'
#' @export
#'
#' @examples download_releases()
download_releases <- function(file="RL041_ALL_FULLSET.zip", dir="RMIS"){
  #if(is.null(dir)) dir <- "RMIS"
  url <- file.path(get("url",env=RMIS.globals), get("rel_file",env=RMIS.globals))
  #dir <- file.path(url, file)
  if(!dir.exists(dir)) dir.create(dir,recursive=TRUE)
  message("Downloading Release data from RMIS to ~./", dir,".")
  download.file(url=url, 
                destfile=file.path(dir,get("rel_file",env=RMIS.globals)), 
                quiet=TRUE)
}

RMIS.globals <- new.env()
RMIS.globals$url <- "ftp://ftp.rmpc.org/pub/data"
RMIS.globals$rel_file <- "RL041_ALL_FULLSET.zip"

```

```{r function-2}
#' Download RMIS LUTs
#' @description Downloads lookup tables from RMIS ftp server.
#' @param url url to RMIS ftp serer 
#' @param lut_dir Directory to save RMIS lookup tables. If `NULL` (the default) puts luts in a RMIS_LUTs folder in working directory.
#' @return `NULL`
#' @return Downloads lookup tables from RMIS into chosen dir
#' @export
download_luts <- function(lut_dir="RMIS/LUTs"){
  #require(parallel)
  #require(doParallel)
  #require(foreach)
url <- get("url",RMIS.globals)
 # if(is.null(dir)) {dir <- "RMIS/LUTs"}
    if(!dir.exists(lut_dir)) {dir.create(lut_dir,recursive=TRUE) }

  #lut_dir <- dir
  
  lut_filenames <- c("LC041_ALL_FULLSET.zip",
                    "run.zip",
                    "species.zip",
                    "study_type.zip",
                    "marks.zip",
                    "location_type.zip",
                    "gear.zip", 
                    "fishery.zip",
                    "period.zip",
                    "adclip_selective_fishery.csv"
                    )

    ftp_paths <- file.path(url, lut_filenames)
    dest_paths <- file.path(lut_dir, lut_filenames)                
   
       cl <- parallel::makeCluster(parallel::detectCores())
      
       doParallel::registerDoParallel(cl=cl)
     
message("Downloading LUTs from RMIS to ~./",lut_dir,".")

  foreach::foreach(i=seq_along(ftp_paths)) %dopar% {
    download.file(url=ftp_paths[i], destfile=dest_paths[i], quiet=TRUE)
    } %>% 
      invisible()
    stopCluster(cl)
} 


```

```{r function-3}
#' Make a list of files to download
#' @description Creates a list of files to download for desired years of CWT recovery data.
#' @param startYear First year of desired CWT recovery data
#' @param endYear  Last year of desired CWT recovery data
#' @param RMIS_url URL to RMIS ftp server
#' @param temp_dir File to hold downloaded csv's
#' @importFrom RCurl getURL
#' @return A list with download urls for each file and destination paths for each file
#'
#' @examples
make_file_list <- function(startYear, 
                              endYear,
                              RMIS_url="ftp://ftp.rmpc.org/pub/data/", 
                              dir=NULL) {
# # Error message
#   if(is.null(startYear) | is.null(endYear)) {

#     return(message("ERROR: Please supply start and/or end year"))
#   }
  
  # load pkgs required for this function
    #using("RCurl", "tidyverse")
  
# Get filenames in the RMIS ftp directory - Takes a minute
ftp_names <- RCurl::getURL(RMIS_url, dirlistonly = TRUE)

# Make a vector of filenames, separating by line breaks ("\n")
  filenames <- strsplit(ftp_names, "\n") [[1]]

# Only want the csv files, use the regex below to grab only files beginning with RC041_ and ending with .csv
    # Changed to .zip to help with download speed. readr can read from local zips but not url .zips
  csvs <- filenames[grep("^RC041_.*\\.zip", filenames)]

  #  Only grab ODFW/WDFW files, replace line 22 with:
  #   csvs <-  filenames[grep("^RC041_ODFW.*\\.csv | ^RC041_WDFW.*\\.csv", filenames,fixed=F)]

# Extract the years for each recovery filename,convert to number. used to filter out years we don't need
  yrs <- substr(csvs, start=nchar(csvs)-8, nchar(csvs)-5) %>% as.integer

# Subset the csv filenames for only the years we want, drop the "\r" from filenames (for when we go to download) 
  files <- csvs[which(yrs >= startYear & yrs<=endYear)] %>% substr(1, nchar(.)-1)

# Return the list with a vector of file urls and the local path to save the downloaded files
  list(download_urls=paste0(RMIS_url, files), files=file.path(dir,files))
}

```

```{r function-4}
#' Download CWT recoveries
#'
#' @param start_yr First year of recoveries 
#' @param end_yr  Last year of recoveries
#' @param dir Directory to save downloaded files, if `NULL` creates Data/Recoveries/temp in working directory.
#' @param by_brood  `TRUE` (default) if start and end years are in terms of brood years
#'
#' @return `NULL`
#' @return Downloads .zip files of recovery data to local dir
#' @export
#'
#' @examples
download_recoveries <- function(start_yr, end_yr, by_brood=TRUE, dir="RMIS/Recoveries") {

  #if(is.null(dir)) dir <- "RMIS/Recoveries"
  if(!dir.exists(dir)){dir.create(dir, recursive=TRUE)}

  if(by_brood){
    
  startYear <- start_yr + 2
  endYear <- end_yr + 7
  
  }else{
    startYear <- start_yr
    endYear <- end_yr
  }
  
  curYear <- lubridate::year(Sys.Date())
  
  if (startYear > (curYear-1) || (endYear > (curYear-1))){
    warning(paste0("Chosen brood year(s) may not be fully reported to RMIS"))
    }
  
  # BUILD TEST FOR COMPLETED BROODs- maybe year(sys.Date()-1)?
  #if(endYear>)
   # Create list with the file  paths
      file_list <- make_file_list(startYear, endYear, dir=dir)

    # Set up clusters for parallel downloads
      cl <- makeCluster(detectCores())
        
      registerDoParallel(cl=cl)
      
message("This could take a while.")

  # Do download, read and combine the csvs with parallel for loop
     foreach(i=seq_along(file_list[[1]]), .inorder=FALSE) %dopar% {

      # Download the files from download urls, save them to the local paths
       download.file(url=file_list$download_urls[i], destfile=file_list$files[i], quiet=TRUE)
       
    }
    
stopCluster(cl)

}

```

```{r function-5}
#' Read release data
#'
#' @param first_by first brood year of data
#' @param last_by  last brood year of data
#' @param dir Directory where release data were downloaded
#' @import readr
#' @return A data frame of the raw RMIS release data, filtered for brood years between first_by and last_by (inclusive)
#' 
#' @examples
read_releases <- function(first_by=NULL, last_by=NULL, dir="RMIS"){
  #require(readr)
 # if(is.null(dir)){dir <- "RMIS"}
  file <- file.path(dir, get("rel_file",env=RMIS.globals))
  
  if(!file.exists(file)){download_releases(dir=dir)}
  
 if (!is.null(first_by) & !is.null(last_by)) {  
  read_csv(file, 
           col_types=cols(.default="c",
                          species="i",
                          run="i",
                          avg_weight="d",
                          cwt_1st_mark_count="d",
                          cwt_2nd_mark_count="d",
                          non_cwt_1st_mark_count="d",
                          non_cwt_2nd_mark_count="d",
                          brood_year="i",
                          tag_loss_rate="d",
                          avg_length="d",
                          tag_loss_sample_size="i",
                          tag_loss_days="d"), 
           progress=FALSE)%>% 
    # Filter for Chinook (1) and Coho (2)
    filter( brood_year >= first_by, 
            brood_year <= last_by)
 } else {
   read_csv(file, 
           col_types=cols(.default="c",
                          species="i",
                          run="i",
                          avg_weight="d",
                          cwt_1st_mark_count="d",
                          cwt_2nd_mark_count="d",
                          non_cwt_1st_mark_count="d",
                          non_cwt_2nd_mark_count="d",
                          brood_year="i",
                          tag_loss_rate="d",
                          avg_length="d",
                          tag_loss_sample_size="i",
                          tag_loss_days="d"), 
           progress=FALSE)
  
 }
}  


```

```{r function-6}
#' Lookup foreign keys in RMIS release data
#'
#' @param RMIS_releases read in from read_releases()
#' @param lut_dir Directory with RMIS lookup tables if `NULL` (default) looks in Data/RMIS_LUTs 
#' @return Dataframe of RMIS release data with decoded field names.
#' 
#'
decode_release_data <- function(RMIS_releases, lut_dir="RMIS/LUTs"){
 
  if(!dir.exists(lut_dir) | length(list.files(lut_dir))==0){
    download_luts(lut_dir=lut_dir)
    }
  
 # Read lookup tables
  RMIS_locations <- read_csv(file.path(lut_dir,"LC041_ALL_FULLSET.zip"), col_types=cols(.default="c"),progress=FALSE)
  RMIS_runs <- read_csv(file.path(lut_dir,"run.zip"), col_types=cols(.default="c",run="i"),progress=FALSE)
  RMIS_species <- read_csv(file.path(lut_dir,"species.zip"), col_types=cols(.default="c",species="i"),progress=FALSE)
  RMIS_studytype <- read_csv(file.path(lut_dir,"study_type.zip"), col_types=cols(.default="c"),progress=FALSE)
  
  missing_release_locs <- which(is.na(RMIS_releases$release_location_code) | 
                                  RMIS_releases$release_location_code=="" | 
                                  grepl("TEMP",RMIS_releases$release_location_code))

  missing_domains <- RMIS_releases %>% 
    dplyr::filter(grepl("TEMP", .$release_location_code) | is.na(release_location_code) | release_location_code == "") %>% 
  left_join(filter(RMIS_locations, location_type == 3), by=c("hatchery_location_code"="location_code")) %>% 
  select(tag_code_or_release_id, psc_region) %>% 
  left_join(RMIS_domain, by=c("psc_region"="rmis_region")) %>% 
    select(rmis_domain)

CR_rel_data <- 

  # Filter the releases for brood years, grab all years for both release summary and tag recoveries  
  RMIS_releases %>% 
  # Then join to the location table (type 4 = release locations) to lookup the release site name and psc region
    left_join(
    
    #Select just the location code and name from the locations table to join to the releases
      select(filter(RMIS_locations,location_type==4), location_code, release_site=name, psc_region),
  
    #Join the release data to the filtered location table (line above) by release location code and RelCode (named in line above: "RelCode=location_code")
      by=c("release_location_code"="location_code")) %>% 
  
    # Join the psc region looked up above to the rmis_domain table to lookup the RMIS domain,
      left_join(RMIS_domain, by=c("psc_region"="rmis_region")) %>%
  
    # Join to the location table again, this time lookup hatchery name
      left_join(
      select(filter(RMIS_locations, location_type==3), location_code, hatchery=name),
      by=c("hatchery_location_code"="location_code")) %>%
    
    # Join to location table one last time to lookup stock name
      left_join(
      select(filter(RMIS_locations, location_type==5), location_code, stock=name),
      by=c("stock_location_code"="location_code")) %>%   
  
    left_join(select(RMIS_species, species, species_name), by=c("species")) %>% 
    left_join(RMIS_runs, by="run") %>% 
    left_join(RMIS_studytype, by="study_type") %>% 
  
    mutate(release_year=substr(last_release_date, 1, 4)) #%>%
  
    # Finally, select only the columns needed.
    #select(record_code,tag_code_or_release_id,reporting_agency, species=species_name, run=run_name, tag_code_or_release_id, Hatchery, Stock, RelSite,brood_year,first_release_date, last_release_date,release_year,rmis_domain,
    #       cwt_1st_mark, cwt_1st_mark_count,non_cwt_1st_mark,non_cwt_1st_mark_count,cwt_2nd_mark,
    #       cwt_2nd_mark_count,non_cwt_2nd_mark,non_cwt_2nd_mark_count,release_location_code,study_type=study_type_name,avg_weight,rel_id,comp_key)

# Lookup the rmis domain for the missing domains, replace in CR_rel_data
CR_rel_data[which(is.na(CR_rel_data$rmis_domain)), "rmis_domain"] <- 
  
  CR_rel_data[which(is.na(CR_rel_data$rmis_domain)),] %>% 
  left_join(filter(RMIS_locations,location_type==3), by=c("hatchery_location_code"="location_code")) %>%
  left_join(RMIS_domain, by=c("psc_region.y"="rmis_region")) %>% 
  select(rmis_domain.y)

# Check for agencies with releases having undefined domains
agencies_no_domain <- CR_rel_data %>% 
  filter(is.na(rmis_domain)) %>% 
  select(release_agency) %>% 
  distinct()

# # Print warning for missing rmis_domains. Col R are usually reported, have seen WDFW coastal data with no domain
# if(nrow(agencies_no_domain)>0){
#   warning(paste(nrow(agencies_no_domain),"agencies have undefined release domains."), 
#           paste(c(" Agencies include:", pull(agencies_no_domain, release_agency)), collapse=" "))
# }

# Change release date to date format
 CR_rel_data %>% 
   
   #tibble(last_release_date=c("20200507","202004","2020",NA)) %>% 
   mutate(date_len=stringr::str_length(last_release_date)) %>% 
   mutate(last_release_date=case_when(date_len==4 ~ paste0(last_release_date,"0101"), # only year reported to RMIS YYYY
                                      date_len==6 ~ paste0(last_release_date,"14"),   # only month reported to RMIS YYYYmm
                                      date_len==8 ~ last_release_date)) %>%   # full date reported YYYYmmdd
   mutate(last_release_date=lubridate::ymd(last_release_date))

 }

```

```{r function-7}
#' Filter and combine recoveries
#'
#' @param first_by 
#' @param last_by 
#' @param rec_dir Directory where recovery data were downloaded
#' @param ... filter conditions for RMIS fields in release data 
#' @importFrom rlang quos
#' @importFrom rlang !!!
#' @return
#' @export
#'
#' @examples
filter_and_combine_recoveries <- function(first_by, last_by, ..., rec_dir="RMIS/Recoveries", lut_dir="RMIS/LUTs" ){
  
  if(!dir.exists(rec_dir) || length(list.files(rec_dir))==0){stop("No recovery data found")}
  
  # Create quosure for filter conditions passed in: need to document examples. 
  # Can pass in any filter conditions using RMIS field names.
  filter_conditions <- rlang::quos(...)

  files <- list.files(rec_dir, full.names=TRUE)

  Releases <- read_releases() %>% decode_release_data()
  
  species_lu <- read_csv(file.path(lut_dir,"species.zip"), 
                         col_types=cols(species=col_integer(), 
                                        species_name=col_character(),
                                        species_name=col_character())) %>% 
                select(species,species_name)
                                                                 
  # Set up clusters for parallel read/filter/combine
      cl <- makeCluster(detectCores())
      
  # Register cluster      
      registerDoParallel(cl=cl)  
  message("Reading recovery files, please be patient.")
# Read, lookup release info, filter in parallel
df <- foreach(i=seq_along(files), .combine=rbind, .inorder=FALSE, .packages=c("tidyverse")) %dopar% {

    read_csv(files[i], col_types=cols(.default="c", 
                                      recovery_date=col_date(format="%Y%m%d"),
                                      run_year=col_integer(),
                                      species=col_integer(),
                                      estimated_number=col_double())) %>%
    # Look up recovery species
    left_join(species_lu, by="species") %>% 
    # Look up release info
    left_join(Releases, by=c("tag_code"="tag_code_or_release_id"), suffix=c("_recovery","")) %>%
   
    # Filter by conditions passed in as '...'
    filter(!!!filter_conditions,
           # Type 5 recoveries can lead to double counting, check RMIS manual
           sample_type!=5, 
           # Only succesfully decoded recoveries
           tag_status==1,
           brood_year>=first_by,
           brood_year<=last_by,
           run_year>=first_by+2,
           run_year<=last_by+7)

  } # End parallel for loop

    # Stop the parallel cluster
        stopCluster(cl)
  
#  Return df      
  df
      
    # Write out the combined dataframe as a csv
    #write.csv(df, paste0("GatherData/", "recoveries.csv"),row.names=FALSE)
    
    # Delete the downloaded csvs in the temp directory
      #file.remove(file_list$local_paths) %>% invisible()
  
}

```

```{r function-8}
#' Lookup recovery location/fishery info
#'
#' @param recoveries A dataframe of recovery data from RMIS
#'
#' @return A dataframe with foreign keys decoded from LUTs
#' @export
#'
#' @examples
tidy_recoveries <- function(recoveries,lut_dir="RMIS/LUTs") {
  #using("readxl") 
  
  RMIS_recoveries <- recoveries %>%  mutate(temp_prefix = NA)#overies 

  gear_lu <- read_csv(file.path(lut_dir,"gear.zip"), col_types = cols(fishery = "d"))
  
  fishery_lu2 <- read_csv(file.path(lut_dir,"fishery.zip"), col_types = cols(fishery = "d"))
  
  RMIS_locations <- read_csv(file.path(lut_dir,"LC041_ALL_FULLSET.zip"), col_types = cols(.default = "c"), progress=FALSE)

  # Get unique recovery location/fishery rows from recoveries, used to create a mgt fishery lut for the recoveries
    unique_rec_locs <- RMIS_recoveries %>% select(recovery_location_code,fishery) %>% distinct() %>% mutate(temp_prefix=NA)

  # Matches the fishery prefix to corresponding row(s) in the fishery_lu
    mgt_fishery_lu <-
  
    sapply(1:nrow(unique_rec_locs), function(x)
  which(startsWith(unique_rec_locs$recovery_location_code[x], prefix = fishery_lu$location_code_prefix) &
          unique_rec_locs$fishery[x] >= fishery_lu$starting_psc_fishery & unique_rec_locs$fishery[x] <= fishery_lu$ending_psc_fishery)
      )

  no_codes <-
    sapply(1:length(mgt_fishery_lu), function(x)
      length(mgt_fishery_lu[[x]])) == 0
  
  
  unique_rec_locs$temp_prefix[no_codes] <- "X"
  
  mgt_fishery_lu[which(unique_rec_locs$temp_prefix == "X")] <-
    sapply(which(unique_rec_locs$temp_prefix == "X"), function(x)
      which(
        startsWith(unique_rec_locs$temp_prefix[x], prefix = fishery_lu$location_code_prefix) &
          unique_rec_locs$fishery[x] >= fishery_lu$starting_psc_fishery &
          unique_rec_locs$fishery[x] <= fishery_lu$ending_psc_fishery
      ))
  
  no_codes <-
    sapply(1:length(mgt_fishery_lu), function(x)
      length(mgt_fishery_lu[[x]])) == 0
  
  mgt_fishery_lu[no_codes] <- NA
  
  # Matches with >1 corresponding fishery codes
  to_fix <-sapply(1:length(mgt_fishery_lu), function(x) length(mgt_fishery_lu[[x]])) > 1
  
  if(any(to_fix)){
  # Replace with the longest match
    for (i in 1:length(mgt_fishery_lu[to_fix])) {
      mgt_fishery_lu[to_fix][[i]] <- mgt_fishery_lu[to_fix][[i]][which.max(nchar(fishery_lu$location_code_prefix[mgt_fishery_lu[to_fix][[i]]]))]
    }
  }
  
  mgt_fishery_lu <- unlist(mgt_fishery_lu)
  
  rec_fishery_lu <- bind_cols(unique_rec_locs, mgt_fishery=fishery_lu$mgt_fishery_name[mgt_fishery_lu]) %>% 
                    select(- temp_prefix)

  RMIS_recoveries %>% 
    left_join(rec_fishery_lu, by=c("recovery_location_code","fishery")) %>% 
    #select(tag_code,recovery_date,mgt_fishery) %>% 
    left_join(select(filter(RMIS_locations,location_type==1), location_code, recovery_location=name, description, psc_region), by=c("recovery_location_code"="location_code")) %>% 
    left_join(fishery_lu2 %>% mutate(fishery=as.character(fishery)),by="fishery") %>% 
    left_join(gear_lu %>% mutate(fishery=as.character(fishery)), by = c("reporting_agency_recovery"="reporting_agency", "fishery", "gear")) %>% 
    mutate(age=run_year - brood_year)
      
}

```

```{r function-9}
#' Download dataframe of the RMIS release data
#'
#' @param first_by first brood year of releases 
#' @param last_by  last brood year of releases
#' @param dir directory where releases are held if `NULL` (the default) creates a Data folder in working directory.
#' @param lut_dir directory where releases are held
#' @param dl_now  Logical determines if release file should be downloaded now (if already present in `rel_dir`). Defaults to FALSE.
#' @return A dataframe of the RMIS release data with foreign keys decoded.
#' @export
#'
get_release_data <- function(first_by=NULL, last_by=NULL, rel_dir="RMIS",lut_dir="RMIS/LUTs", dl_now=FALSE){
  #if(is.null(dir))dir <- "RMIS"
  rel_file <- file.path(rel_dir,get("rel_file",env=RMIS.globals))
 
  if( dl_now==TRUE | !file.exists(rel_file)) {download_releases(dir=rel_dir)}
    if(dl_now==TRUE | length(list.files(lut_dir))==0) {download_luts(lut_dir=lut_dir)}
  
  read_releases(first_by=first_by, 
                last_by=last_by,
                dir=rel_dir) %>% 
    decode_release_data(lut_dir=lut_dir)
}
```

```{r function-10}
#' set the RMIS ftp url
#'
#' @param url 
#'
#' @return
#' @export
#'
#' @examples
set_url <- function (url) {
    RMIS.globals$url <- url
}
```

```{r function-11}
#' Set the RMIS release file name
#' only necessary to use if RMIS changes this filename
#' @param filename 
#'
#' @return
#' @export
#'
#' @examples
set_release_filename <- function(filename){
  RMIS.globals$rel_file <- filename
}

```


```{r function-12}
#' prep release data for tag rate calculations
#'
#' @param release_data 
#'
#' @return Table with a row for each tag_code_or_release_id, with 4 new columns for CWT and clip status: AdClipped_CWT, AdClipped_NoCWT, Unclipped_CWT, Unclipped_NoCWT and a composite key of species,hatchery,run,stock,release location for grouping when doing tagrate calcs
#' 
#'
#' @examples
releases_for_tr <- function(release_data){
  # function works as follows:
  # 1) strip tag nums/marks from raw release data i.e., columns cwt_1st... cwt_2nd etc....
  # 2) filter original data by mark (1st and 2nd) for Ad and unclipped
  # 3) rename count column with cwt and mark status
  # 4) bind rows with same cwt and mark status (i.e., same mark/cwt from 'cwt_1st' and 'cwt_2nd' columns)
  # 5) join all the bound tables together to the tag info in step 1 by tag code

  d <- release_data

 d %>% 
  mutate(LastRelDate=last_release_date) %>% 
  tidyr::unite(col=comp_key, 
               species,
               hatchery_location_code, 
               run, 
               stock_location_code, 
               release_location_code, 
               brood_year,remove=FALSE) %>% 
   
  # First, drop cwt_1st, 2nd etc. from raw release data (retains tag info but not marks/counts)
select(-c(cwt_1st_mark,
          cwt_1st_mark_count,
          cwt_2nd_mark,
          cwt_2nd_mark_count,
          non_cwt_1st_mark,
          non_cwt_1st_mark_count,
          non_cwt_2nd_mark,
          non_cwt_2nd_mark_count)) %>% 
  
#  Join tag info to AdCWT
  left_join(
    bind_rows(
      # Bind rows Ad-clippped with CWT
      d %>% select(tag_code_or_release_id, cwt_1st_mark, cwt_1st_mark_count) %>% 
            filter(cwt_1st_mark >= 5000) %>% 
            transmute(tag_code_or_release_id,
                      Ad_CWT=cwt_1st_mark_count),
      
      d %>% select(tag_code_or_release_id, cwt_2nd_mark, cwt_2nd_mark_count) %>% 
            filter(cwt_2nd_mark >= 5000) %>% 
            transmute(tag_code_or_release_id,
                      Ad_CWT=cwt_2nd_mark_count))%>% 
      group_by(tag_code_or_release_id) %>% 
      summarise_all(sum), 
    by="tag_code_or_release_id"
  ) %>% 
  
# Join to AdNoCWT
  left_join(
    bind_rows(
      # Bind rows Ad-clipped, no CWTs
      d %>% select(tag_code_or_release_id, non_cwt_1st_mark, non_cwt_1st_mark_count) %>% 
            filter(non_cwt_1st_mark >= 5000) %>% 
            transmute(tag_code_or_release_id,
                      Ad_NoCWT=non_cwt_1st_mark_count),
      
      d %>% select(tag_code_or_release_id, non_cwt_2nd_mark, non_cwt_2nd_mark_count) %>% 
            filter(non_cwt_2nd_mark >= 5000) %>% 
            transmute(tag_code_or_release_id,
                      Ad_NoCWT=non_cwt_2nd_mark_count)) %>% 
      group_by(tag_code_or_release_id) %>% 
      summarise_all(sum),
    by="tag_code_or_release_id"
  ) %>% 
  
# Join to NoClip CWT  
  left_join(
    # Bind unclipped with CWT
    bind_rows(d %>%
              select(tag_code_or_release_id, cwt_1st_mark, cwt_1st_mark_count) %>% 
              filter(cwt_1st_mark < 5000) %>% 
              transmute(tag_code_or_release_id,
                        Unclipped_CWT=cwt_1st_mark_count),
              d %>%
              select(tag_code_or_release_id, cwt_2nd_mark, cwt_2nd_mark_count) %>% 
              filter(cwt_2nd_mark < 5000) %>% 
              transmute(tag_code_or_release_id, 
                        Unclipped_CWT=cwt_2nd_mark_count))%>% 
      group_by(tag_code_or_release_id) %>% 
      summarise_all(sum),
    by="tag_code_or_release_id"
  ) %>% 
  
# Join to Unclipped No CWTs              
  left_join(
    # Bind unclipped with no CWTs
    bind_rows(d %>%
              select(tag_code_or_release_id, non_cwt_1st_mark, non_cwt_1st_mark_count) %>% 
              filter(non_cwt_1st_mark < 5000) %>% 
              transmute(tag_code_or_release_id,
                        Unclipped_NoCWT=non_cwt_1st_mark_count), 
              d %>% 
              select(tag_code_or_release_id, non_cwt_2nd_mark, non_cwt_2nd_mark_count) %>% 
              filter(non_cwt_2nd_mark < 5000) %>% 
              transmute(tag_code_or_release_id, 
                        Unclipped_NoCWT=non_cwt_2nd_mark_count))%>% 
      group_by(tag_code_or_release_id) %>% 
      summarise_all(sum),
    
    by="tag_code_or_release_id") %>% 
   mutate_at(vars(contains("CWT")), ~tidyr::replace_na(.x, 0)) %>% # replace NA counts in new columns with 0
   mutate(DIT=if_else(Ad_CWT==0,"DIT",NA_character_)) # tag codes or id's with no Ad CWT releases are considered DIT groups

}


```

```{r function-13}
#' Add group ids to releases 
#' groups multiple tag codes released from the same hatchery if released within 3 weeks and 4.5 grams avg wt.
#'
#' @param release_data 
#'
#' @return
#' 
#'
#' @examples
group_releases <- function(release_data){

d2 <- release_data %>% 
  filter(!is.na(last_release_date)) 

# Assign release groups ####

# Unique releases
unique_rels <- unique(d2$comp_key)

# Empty vector to put release ids 
rel.id <- vector("integer", length=length(d2$comp_key))

# Progress bar 
#pb <- txtProgressBar(min=0,max=length(unique_rels),char="><((*> ", style=3, width=10)

# For each unique release group     
for (i in 1:length(unique_rels)) {
     #i <- 1
 # Subset original data for only the releases from unique release [i]
      d <- subset(d2, d2$comp_key == unique_rels[i], drop = F)    

 #  The first release for hatchery/release site/ brood year [i] is #1
      id <- 1
         # print(unique_rels[i])
 # While any tags in d have not been assigned a release id 
      while (any(rel.id[match(d$tag_code_or_release_id, d2$tag_code_or_release_id)] == 0)) {
           
       # If any avg weights for d are NA,     
           if (any(is.na(d$avg_weight))) {
                
               # Then identify which tags in d are within 21 days of the minimum date of all the tags in d,
               # the abs () is unnecessary
               g <- which(abs(d$LastRelDate - min(d$LastRelDate,na.rm=TRUE)) <= 21 ) } 
           
     # Otherwise, 
           else {
                
               # identify which tags were released within 21 days of the first release in d 
               # AND 
               # within 4.5 grams of the first release's avg.wt
               g <- which(abs(d$LastRelDate - min(d$LastRelDate,na.rm=TRUE)) <= 21 &  
                            abs(d$avg_weight - min(d$avg_weight[which.min(d$LastRelDate)])) <= 4.5)
           }
           
     # Assign the tags identifed by g (above) the current release number
       rel.id[match(d$tag_code_or_release_id, d2$tag_code_or_release_id)[g]] <- id
     
     # Subset d for the tags with no assigned release numbers   
       d <- d[ which(rel.id[ match(d$tag_code_or_release_id, d2$tag_code_or_release_id) ] == 0), ]
                         #which(d2$tag %in% d$tag)
                         
     # Bump release number up one
       id <- id + 1
          
# Loop back around to While condition
      }
      
      # When while loop for hatchery/rel site/by [i] is done, bump up progress bar 
      # and loop around to next hatchery/release site/ brood year
      
     # setTxtProgressBar(pb, i)
}
#head(d2)
# Add the release ids to the data
 d2$rel_id <-rel.id

d2
}

```

```{r function-14}

#' Calculate tagrates from reshaped release data
#'
#' @param release_data 
#'
#' @return
#' 
#'
#' @examples
calc_tagrates <- function(release_data){
  if(!any(colnames(release_data)=="rel_id")){stop("Release ids have not been assigned. Pipe releases through group_releases() first.")}
  
  release_data %>% group_by(comp_key,rel_id) %>% 
  summarise(Ad_CWT=sum(Ad_CWT,na.rm=TRUE),Ad_NoCWT=sum(Ad_NoCWT,na.rm=TRUE),Unclipped_CWT=sum(Unclipped_CWT,na.rm=TRUE),Unclipped_NoCWT=sum(Unclipped_NoCWT,na.rm=TRUE)) %>% 
  left_join(select(release_data,tag_code_or_release_id,comp_key,rel_id,DIT),by=c("comp_key"="comp_key","rel_id"="rel_id")) %>% 
  mutate(NonMS=Ad_CWT/(Ad_CWT+Ad_NoCWT+Unclipped_CWT+Unclipped_NoCWT), MS=Ad_CWT/(Ad_CWT+Ad_NoCWT)) %>% 
  ungroup %>% 
  left_join(select(release_data, tag_code_or_release_id, record_code),by=c("tag_code_or_release_id"="tag_code_or_release_id")) %>%
  filter(record_code=="T" & is.na(DIT)) %>% 
  select(TagCode=tag_code_or_release_id, MS, NonMS) %>% 
  tidyr::pivot_longer(cols=c(MS,NonMS),names_to="TagRateType",values_to="TR") %>% 
    arrange(TagCode)
  
}

```

```{r function-15}
#' Create a juvenile lookup table txt file
#'
#' @param first_by first brood year to pull
#' @param last_by last brood year to pull
#' @param ... filter conditions for decoded release data e.g., `species_name=="Chinook"`
#'
#' @return
#' @export
#'
#' @examples
juv_tr_lut <- function(first_by, last_by, ...){
  filter_conditions <- rlang::quos(...)

get_release_data(first_by=first_by,last_by=last_by) %>% 
  filter(!!!filter_conditions) %>%  
  releases_for_tr() %>%
  group_releases() %>% 
  calc_tagrates() 
}
```

```{r function-16}
#' Make a tag info lut
#'
#' @param first_by first brood year of releases
#' @param last_by  last brood year of releases
#' @param ...  other filter conditions passed in e.g., `species_name=="Chinook"`
#'
#' @return a table with release info for tag codes that meet brood year and other filter conditions
#' @export
#'
#' @examples
make_tag_info_lut <- function(first_by, last_by,...){
  filter_conditions <- rlang::quos(...)
  get_release_data(first_by=first_by,last_by=last_by) %>% 
    releases_for_tr() %>% 
    filter(record_code=="T",!!!filter_conditions) %>% 
    select(TagCode=tag_code_or_release_id, 
           brood_year,
           agency=release_agency, 
           hatchery, 
           run=run_name,
           stock, 
           release_loc=release_site,
          # rmis_region_name,
          # rmis_domain, 
           DIT)
}
```

# There can be development actions

These will be included in the `dev_history.R` file of your package, but won't be direct part of it.

```{r development-1, eval=FALSE}
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly
fusen::inflate(rmd = "dev/dev_history.Rmd")
```

```{r development-2, eval=FALSE}
# Add fishery map lookup to internal data, this table comes from Jim Longwill. Not on RMIS website
library(readxl)
fishery_lu <-read_xlsx("RMIS_LUTs/rmis_rar_fishery_map.xlsx", sheet = "rar_original_fishery_map", trim_ws = TRUE, progress = FALSE)

usethis::use_data(fishery_lu)

```


# Inflate your package

You're one inflate from paper to box.
Build your package from this very Rmarkdown using `fusen::inflate()`

- Verify your `"DESCRIPTION"` file has been updated
- Verify your function is in `"R/"` directory
- Verify your test is in `"tests/testthat/"` directory
- Verify this Rmd appears in `"vignettes/"` directory

